{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BigQuery APIs\n",
    "\n",
    "Google Cloud Datalab provides an integrated environment for working with Google BigQuery for both ad-hoc, exploratory work as well as pipeline development. You've already seen the use of `%%bq` in the [Hello BigQuery](./Hello BigQuery.ipynb) notebook, and various commands in the [BigQuery Commands](./BigQuery Commands.ipynb) notebook.\n",
    "\n",
    "These BigQuery commands are in fact built using the same BigQuery APIs that are available for your own use. This notebook introduces some examples of using those APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the API\n",
    "\n",
    "The Datalab APIs are provided in the `google.datalab` Python module, and the BigQuery functionality is contained within the `google.datalab.bigquery` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.datalab.bigquery as bq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Data\n",
    "\n",
    "The most important BigQuery-related API is the one that allows you to execute a SQL query. The `google.datalab.bigquery.Query` class provides that functionality. To run a query using BigQuery Standard SQL, create a new `Query` object with the desired SQL string, or use an object that has already been defined by the `%%bq query --name` command. Let's take a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and run a SQL query\n",
    "httplogs_query = bq.Query('SELECT * FROM `cloud-datalab-samples.httplogs.logs_20140615` LIMIT 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the query created above with caching turned off, so we're sure to be able to retrieve metadata, such as bytes processed from resulting query job.\n",
    "\n",
    "For this, we'll need to use a `QueryOutput` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResultsTable job_TSvMKPe0_YW_HH4uAEFCNxnGQ-JU"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_options = bq.QueryOutput.table(use_cache=False)\n",
    "result = httplogs_query.execute(output_options=output_options).result()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result object is a `QueryResultsTable` class, and can be enumerated in the same manner a regular Python list, in addition to retrieving metadata about the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM `cloud-datalab-samples.httplogs.logs_20140615` LIMIT 3\n",
      "3 rows\n",
      "24152138 bytes processed\n"
     ]
    }
   ],
   "source": [
    "# Inspecting the result, and the associated job\n",
    "print(result.sql)\n",
    "print(str(result.length) + ' rows')\n",
    "print(str(result.job.bytes_processed) + ' bytes processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'timestamp': datetime.datetime(2014, 6, 15, 8, 12, 39, 711942),\n",
       "  'latency': 256,\n",
       "  'status': 200,\n",
       "  'method': 'GET',\n",
       "  'endpoint': 'Home'},\n",
       " {'timestamp': datetime.datetime(2014, 6, 15, 10, 26, 53, 442199),\n",
       "  'latency': 256,\n",
       "  'status': 200,\n",
       "  'method': 'GET',\n",
       "  'endpoint': 'Home'},\n",
       " {'timestamp': datetime.datetime(2014, 6, 15, 13, 4, 58, 103063),\n",
       "  'latency': 256,\n",
       "  'status': 200,\n",
       "  'method': 'GET',\n",
       "  'endpoint': 'Home'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the programmatic representation.\n",
    "# Converting the QueryResultsTable to a vanilla list enables viewing the literal data,\n",
    "# as well as side-stepping the HTML rendering seen above.\n",
    "list(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `QueryResultsTable` has more functionality you can explore, such as converting it to a pandas dataframe, or exporting to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>latency</th>\n",
       "      <th>status</th>\n",
       "      <th>method</th>\n",
       "      <th>endpoint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-06-15 08:12:39.711942</td>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-06-15 10:26:53.442199</td>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-06-15 13:04:58.103063</td>\n",
       "      <td>256</td>\n",
       "      <td>200</td>\n",
       "      <td>GET</td>\n",
       "      <td>Home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp  latency  status method endpoint\n",
       "0 2014-06-15 08:12:39.711942      256     200    GET     Home\n",
       "1 2014-06-15 10:26:53.442199      256     200    GET     Home\n",
       "2 2014-06-15 13:04:58.103063      256     200    GET     Home"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result.to_dataframe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling Data\n",
    "\n",
    "Let's take a look at a sampling query. Consider the following query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UniqueNames2013 = bq.Query(sql='''\n",
    "  WITH UniqueNames2013 AS\n",
    "  (SELECT DISTINCT name\n",
    "    FROM `bigquery-public-data.usa_names.usa_1910_2013`\n",
    "    WHERE Year = 2013)\n",
    "  SELECT * FROM UniqueNames2013\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute the query and view a sample from the result table, use a `Sampling` object, let's use random sampling for this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QueryResultsTable job_6D7JK_FmeC4CeG330YnVJLKfuo1n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling = bq.Sampling.random(percent=2)\n",
    "job = UniqueNames2013.execute(sampling=sampling)\n",
    "job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice every time we run the query above, we get a different set of results, since we chose a random sampling of 2%.\n",
    "\n",
    "We can also run the query and copy the sampled result into a pandas DataFrame directly. For that, we use a `QueryOutput` object of type `dataframe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_options = bq.QueryOutput.dataframe(max_rows=10)\n",
    "job = UniqueNames2013.execute(output_options=output_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aubrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lillian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ella</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skylar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Angel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Faith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Zoe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Heidi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name\n",
       "0     Lily\n",
       "1   Aubrey\n",
       "2  Lillian\n",
       "3     Ella\n",
       "4   Skylar\n",
       "5    Angel\n",
       "6    Faith\n",
       "7      Zoe\n",
       "8     Lola\n",
       "9    Heidi"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and Tables\n",
    "\n",
    "In addition to executing queries, BigQuery objects like Datasets, Tables and their Schemas can be accessed programmatically as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetName(project_id='cloud-datalab-samples', dataset_id='appenginelogs')\n",
      "DatasetName(project_id='cloud-datalab-samples', dataset_id='carprices')\n",
      "DatasetName(project_id='cloud-datalab-samples', dataset_id='httplogs')\n"
     ]
    }
   ],
   "source": [
    "from google.datalab import Context\n",
    "datasets = bq.Datasets(Context('cloud-datalab-samples', Context.default().credentials))\n",
    "for ds in datasets:\n",
    "  print(ds.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing (100 rows - 4586 bytes)\n",
      "training (417 rows - 19086 bytes)\n"
     ]
    }
   ],
   "source": [
    "sample_dataset = list(datasets)[1]\n",
    "tables = sample_dataset.tables()\n",
    "for table in tables:\n",
    "  print('%s (%d rows - %d bytes)' % (table.name.table_id, table.metadata.rows, table.metadata.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timestamp', 'latency', 'status', 'method', 'endpoint']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = bq.Table('cloud-datalab-samples.httplogs.logs_20140615')\n",
    "fields = map(lambda tsf: tsf.name, table.schema)\n",
    "list(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new dataset (this will be deleted later in the notebook)\n",
    "sample_dataset = bq.Dataset('apisample')\n",
    "sample_dataset.create(friendly_name = 'Sample Dataset', description = 'Created from Sample Notebook')\n",
    "sample_dataset.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To create a table, we also need to create a schema.\n",
    "# We've seen before how to create a schema from some existing data,\n",
    "# let's now try creating it from a list of records:\n",
    "schema = [\n",
    "  {'name': 'name', 'type': 'STRING'},\n",
    "  {'name': 'value', 'type': 'INT64'},\n",
    "  {'name': 'flag', 'type': 'BOOL', 'mode': 'NULLABLE'}\n",
    "]\n",
    "sample_schema = bq.Schema.from_data(schema)\n",
    "\n",
    "sample_table = bq.Table(\"apisample.sample_table\").create(schema = sample_schema, overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BigQuery Schema - Fields:\n",
       "[{'name': 'name',\n",
       "  'type': 'STRING'},\n",
       " {'name': 'value',\n",
       "  'type': 'INT64'},\n",
       " {'mode': 'NULLABLE',\n",
       "  'name': 'flag',\n",
       "  'type': 'BOOL'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_table.schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the cell, below, to see the contents of the new dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[BigQuery Table - name: ajhamilton-scratch.apisample.sample_table]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sample_dataset.tables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear out sample resources\n",
    "sample_dataset.delete(delete_contents = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking Ahead\n",
    "\n",
    "This notebook covered a small subset of the APIs. Subsequent notebooks cover additional capabilities, such as importing and exporting data into and from BigQuery tables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalab-notebooks",
   "language": "python",
   "name": "datalab-notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
