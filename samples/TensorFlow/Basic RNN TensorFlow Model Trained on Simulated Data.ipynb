{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series prediction using RNNs, with TensorFlow\n",
    "\n",
    "This notebook illustrates:\n",
    "\n",
    "* Creating a Recurrent Neural Network in TensorFlow\n",
    "* Creating a Custom Estimator in tf.contrib.learn\n",
    "\n",
    "\n",
    "This notebook was modified based on [the work](http://dataconomy.com/2017/05/how-to-do-time-series-prediction-using-rnns-tensorflow-and-cloud-ml-engine/) originally published by VALLIAPPA LAKSHMANAN.\n",
    "\n",
    "Send any feedback to datalab-feedback@google.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We simulate a set of sinusoids with random amplitudes and frequencies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xrange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4c76faf4a7fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m   \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsplot\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mcreate_time_series\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0;31m# 5 series\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xrange' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "SEQ_LEN = 40\n",
    "\n",
    "def create_time_series():\n",
    "  freq = (np.random.random() * 0.5) + 0.1  # 0.1 to 0.6\n",
    "  ampl = np.random.random() + 0.5  # 0.5 to 1.5\n",
    "  x = np.sin(np.arange(0, SEQ_LEN) * freq) * ampl\n",
    "  return x\n",
    "\n",
    "for i in xrange(0, 5):\n",
    "  sns.tsplot( create_time_series() );  # 5 series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data to disk.\n",
    "\n",
    "def to_csv(filename, N):\n",
    "  with open(filename, 'w') as ofp:\n",
    "    for lineno in xrange(0, N):\n",
    "      seq = create_time_series()\n",
    "      line = \",\".join(map(str, seq))\n",
    "      ofp.write(line + '\\n')\n",
    "\n",
    "to_csv('train.csv', 1003)\n",
    "to_csv('eval.csv',  108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -1 eval.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our CSV file sequences consist of 40 numbers. Each number is one input and the prediction output is the next number given previous numbers as history. With 40 numbers (one instance) input, we will have 40 output numbers. For training, each instance's 0~38 numbers are inputs, and 1~39 are truth. For prediction, it is like \"given a series of numbers, predict next n numbers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "We will create a recurrent neural network model based on TensorFlow.\n",
    "\n",
    "For more info on RNN, see:\n",
    "\n",
    "* http://colah.github.io/posts/2015-08-Understanding-LSTMs/ for the theory\n",
    "* https://www.tensorflow.org/tutorials/recurrent for explanations\n",
    "* https://github.com/tensorflow/models/tree/master/tutorials/rnn/ptb for sample code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use TensorFlow's [Estimator](https://www.tensorflow.org/api_docs/python/tf/contrib/learn/Estimator) to build our model. Estimators help construct the training/evaluation/prediction graph. They reuse the common graph, and fork only when needed (i.e. input_fn). They also handle model export. Models exported can be deployed to Google Cloud ML Engine for online prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import shutil\n",
    "import tensorflow.contrib.learn as tflearn\n",
    "import tensorflow.contrib.layers as tflayers\n",
    "from tensorflow.contrib.learn.python.learn import learn_runner\n",
    "from tensorflow.contrib.learn.python.learn.utils import saved_model_export_utils\n",
    "import tensorflow.contrib.rnn as rnn\n",
    "\n",
    "\n",
    "# tf.decode_csv requires DEFAULTS to infer data types and default values.\n",
    "DEFAULTS = [[0.0] for x in xrange(0, SEQ_LEN)]\n",
    "\n",
    "# The Estimator API requires named features.\n",
    "TIMESERIES_FEATURE_NAME = 'rawdata'\n",
    "\n",
    "# Training batch size.\n",
    "BATCH_SIZE = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "Our CSV file structure is quite simple -- a bunch of floating point numbers (note the type of DEFAULTS). We ask for the data to be read BATCH_SIZE sequences at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_fn(filename, mode=tf.contrib.learn.ModeKeys.TRAIN):  \n",
    "  \"\"\"Creates an input_fn for estimator in training or evaluation.\"\"\"\n",
    "  \n",
    "  def _input_fn():\n",
    "    \"\"\"Returns named features and labels, as required by Estimator.\"\"\"  \n",
    "    # could be a path to one file or a file pattern.\n",
    "    input_file_names = tf.train.match_filenames_once(filename)\n",
    "    \n",
    "    filename_queue = tf.train.string_input_producer(\n",
    "        input_file_names, num_epochs=None, shuffle=True)\n",
    "    reader = tf.TextLineReader()\n",
    "    _, value = reader.read_up_to(filename_queue, num_records=BATCH_SIZE)\n",
    "\n",
    "    # parse the csv values\n",
    "    batch_data = tf.decode_csv(value, record_defaults=DEFAULTS)\n",
    "    batch_data = tf.transpose(batch_data) # [BATCH_SIZE, SEQ_LEN]\n",
    "\n",
    "    # Get x and y. They are both of shape [BATCH_SIZE, SEQ_LEN - 1]\n",
    "    batch_len = tf.shape(batch_data)[0]\n",
    "    x = tf.slice(batch_data, [0, 0], [batch_len, SEQ_LEN-1])\n",
    "    y = tf.slice(batch_data, [0, 1], [batch_len, SEQ_LEN-1])\n",
    "    \n",
    "    return {TIMESERIES_FEATURE_NAME: x}, y   # dict of features, target\n",
    "\n",
    "  return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Graph\n",
    "\n",
    "Following Estimator's requirements, we will create a model_fn representing the inference model. Note that this function defines the graph that will be used in training, evaluation and prediction.\n",
    "\n",
    "To supply a model function to the Estimator API, you need to return a ModelFnOps. The rest of the function creates the necessary objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  We will define one LSTM layer. That's the size of LSTM units.\n",
    "LSTM_SIZE = 10\n",
    "\n",
    "\n",
    "def model_fn(features, targets, mode):\n",
    "  \"\"\"Define the inference model.\"\"\"\n",
    "\n",
    "  uniform_initializer = tf.random_uniform_initializer(minval=-0.08, maxval=0.08)\n",
    "  input_seq = features[TIMESERIES_FEATURE_NAME]\n",
    "  \n",
    "  # RNN requires input tensor rank > 2. Adding one dimension.\n",
    "  input_seq = tf.expand_dims(input_seq, axis=-1)\n",
    "  \n",
    "  # LSTM output will be [BATCH_SIZE, SEQ_LEN - 1, lstm_output_size]\n",
    "  lstm_cell = rnn.BasicLSTMCell(LSTM_SIZE)\n",
    "  lstm_outputs, _ = tf.nn.dynamic_rnn(cell=lstm_cell,\n",
    "                                      inputs=input_seq,\n",
    "                                      dtype=tf.float32)\n",
    "  \n",
    "  # Reshape to [BATCH_SIZE * (SEQ_LEN - 1), lstm_output] so it is 2-D and can\n",
    "  # be fed to next layer.\n",
    "  lstm_outputs = tf.reshape(lstm_outputs, [-1, lstm_cell.output_size])\n",
    "  \n",
    "  # Add hidden layers on top of LSTM layer to add some \"nonlinear\" to the model.\n",
    "  hidden1 = tf.contrib.layers.fully_connected(inputs=lstm_outputs,\n",
    "                                              num_outputs=100,\n",
    "                                              activation_fn=None,\n",
    "                                              weights_initializer=uniform_initializer,\n",
    "                                              biases_initializer=uniform_initializer)\n",
    "  \n",
    "  hidden2 = tf.contrib.layers.fully_connected(inputs=lstm_outputs,\n",
    "                                              num_outputs=50,\n",
    "                                              activation_fn=None,\n",
    "                                              weights_initializer=uniform_initializer,\n",
    "                                              biases_initializer=uniform_initializer)  \n",
    "    \n",
    "  predictions = tf.contrib.layers.fully_connected(inputs=hidden2,\n",
    "                                                  num_outputs=1,\n",
    "                                                  activation_fn=None,\n",
    "                                                  weights_initializer=uniform_initializer,\n",
    "                                                  biases_initializer=uniform_initializer)\n",
    "  \n",
    "  # predictions are all we need when mode is not train/eval. \n",
    "  predictions_dict = {\"predicted\": predictions}\n",
    "\n",
    "  # If train/evaluation, we'll need to compute loss.\n",
    "  # If train, we will also need to create an optimizer.\n",
    "  loss, train_op, eval_metric_ops = None, None, None\n",
    "  if mode == tf.contrib.learn.ModeKeys.TRAIN or mode == tf.contrib.learn.ModeKeys.EVAL:\n",
    "    # Note: The reshape below is needed because Estimator needs to know\n",
    "    # loss shape. Without reshaping below, loss's shape would be unknown.\n",
    "    targets = tf.reshape(targets, [tf.size(targets)])\n",
    "    predictions = tf.reshape(predictions, [tf.size(predictions)])\n",
    "    loss = tf.losses.mean_squared_error(targets, predictions)\n",
    "    eval_metric_ops = {\n",
    "      \"rmse\": tf.metrics.root_mean_squared_error(targets, predictions)\n",
    "    }\n",
    "\n",
    "    if mode == tf.contrib.learn.ModeKeys.TRAIN:\n",
    "      # The learning rate here is unusually high, because we don't add any noise\n",
    "      # to training/evaluation data and overfitting is not a big problem.\n",
    "      train_op = tf.contrib.layers.optimize_loss(\n",
    "          loss=loss,\n",
    "          global_step=tf.contrib.framework.get_global_step(),\n",
    "          learning_rate=0.1,\n",
    "          optimizer=\"Adagrad\")\n",
    "  \n",
    "  # return ModelFnOps as Estimator requires.\n",
    "  return tflearn.ModelFnOps(\n",
    "      mode=mode,\n",
    "      predictions=predictions_dict,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Distributed training is launched off using an Experiment.  The key line here is that we use Estimator rather than, say DNNRegressor.  This allows us to provide a model_fn, which will be our RNN defined above.  Note also that we specify a serving_input_fn -- this is how we parse the input data provided to us at prediction time using gcloud or Cloud ML Online Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train():\n",
    "  return create_input_fn('train.csv', mode=tf.contrib.learn.ModeKeys.TRAIN)\n",
    "\n",
    "\n",
    "def get_eval():\n",
    "  return create_input_fn('eval.csv', mode=tf.contrib.learn.ModeKeys.EVAL)\n",
    "\n",
    "\n",
    "def serving_input_fn():\n",
    "  feature_placeholders = {\n",
    "      TIMESERIES_FEATURE_NAME: tf.placeholder(tf.float32, [None, None])\n",
    "  }\n",
    "  return tflearn.utils.input_fn_utils.InputFnOps(\n",
    "      feature_placeholders,\n",
    "      None,\n",
    "      feature_placeholders\n",
    "  )\n",
    "\n",
    "\n",
    "def experiment_fn(output_dir):\n",
    "    \"\"\"An experiment_fn required for Estimator API to run training.\"\"\"\n",
    "\n",
    "    estimator = tflearn.Estimator(model_fn=model_fn,\n",
    "                                  model_dir=output_dir,\n",
    "                                  config=tf.contrib.learn.RunConfig(save_checkpoints_steps=500))\n",
    "    return tflearn.Experiment(\n",
    "        estimator,\n",
    "        train_input_fn=get_train(),\n",
    "        eval_input_fn=get_eval(),\n",
    "        export_strategies=[saved_model_export_utils.make_export_strategy(\n",
    "            serving_input_fn,\n",
    "            default_output_alternative_key=None,\n",
    "            exports_to_keep=1\n",
    "        )],\n",
    "        train_steps=1000\n",
    "    )\n",
    "\n",
    "\n",
    "shutil.rmtree('training', ignore_errors=True) # start fresh each time.\n",
    "learn_runner.run(experiment_fn, 'training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Summary\n",
    "\n",
    "We can plot model's training summary events using Datalab's ML library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.datalab.ml import Summary\n",
    "\n",
    "summary = Summary('./training')\n",
    "summary.plot(['OptimizeLoss/loss', 'loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "We will generate another instance for prediction which is independent on training or evaluation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = create_time_series()\n",
    "\n",
    "# First 30 values as x, Last 10 values as y.\n",
    "prediction_x = list(prediction_data[:30])\n",
    "prediction_y = list(prediction_data[30:])\n",
    "\n",
    "print('x\\n%s\\n' % prediction_x)\n",
    "print('y\\n%s' % prediction_y)\n",
    "\n",
    "sns.tsplot(prediction_x, color='blue')\n",
    "y_truth_curve = [np.nan] * (len(prediction_x)-1) + [prediction_x[-1]] + prediction_y\n",
    "sns.tsplot(y_truth_curve, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First prediction we will do is just sending x, and for each value in x it will return a predicted value. And then we can compare the predicted values with the truth (x+1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model.\n",
    "estimator = tflearn.Estimator(model_fn=model_fn, model_dir='training')\n",
    "\n",
    "# Feed Prediction data.\n",
    "predict_input_fn = lambda: {TIMESERIES_FEATURE_NAME: [prediction_x]}\n",
    "\n",
    "predicted = list(estimator.predict(input_fn=predict_input_fn))\n",
    "predicted = [p['predicted'] for p in predicted]\n",
    "\n",
    "# Plot prediction source.\n",
    "sns.tsplot(prediction_x, color='green')\n",
    "\n",
    "# Plot predicted values.\n",
    "sns.tsplot([prediction_x[0]] + predicted, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next prediction is sending x, and predict next n values. We make n predictions and take only the last predicted value each time, append it to x for next prediction source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = tflearn.Estimator(model_fn=model_fn, model_dir='training')\n",
    "\n",
    "# Prediction data starts with x.\n",
    "x_total = list(prediction_x)\n",
    "\n",
    "# Make n predictions.\n",
    "for i in range(len(prediction_y)):\n",
    "  predict_input_fn = lambda: {TIMESERIES_FEATURE_NAME: [x_total]}\n",
    "  p = list(estimator.predict(input_fn=predict_input_fn))\n",
    "  # For each step, append the tail element of last predicted values.  \n",
    "  x_total.append(p[-1]['predicted'])\n",
    "\n",
    "# The first len(prediction_x) elements are prediction source. So remove them.\n",
    "y_predicted = x_total[len(prediction_x):]\n",
    "\n",
    "# Zero out prediction source (making them nan), add the last value of prediction source\n",
    "# so the first edge in the curve is plotted, and add predicted values.\n",
    "y_predicted_curve = [np.nan] * (len(prediction_x)-1) + [prediction_x[-1]] + y_predicted\n",
    "\n",
    "# Plot prediction source.\n",
    "sns.tsplot(prediction_x, color='blue')\n",
    "\n",
    "# Plot truth curve.\n",
    "sns.tsplot(y_truth_curve, color='green')\n",
    "\n",
    "# Plot predicted curve.\n",
    "sns.tsplot(y_predicted_curve, color='red');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalab-notebooks",
   "language": "python",
   "name": "datalab-notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
