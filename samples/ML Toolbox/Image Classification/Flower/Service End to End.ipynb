{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order of magnitude faster training for image classification: Part II\n",
    "\n",
    "### _Transfer learning using Inception Package - Cloud Run Experience_\n",
    "This notebook continues the codifies the capabilities discussed in this [blog post](http://localhost:8081/). In a nutshell, it uses the pre-trained inception model as a starting point and then uses transfer learning to train it further on additional, customer-specific images. For explanation, simple flower images are used. Compared to training from scratch, the time and costs are drastically reduced.\n",
    "\n",
    "This notebook does preprocessing, training and prediction by calling CloudML API instead of running them in the Datalab container.  The purpose of local work is to do some initial prototyping and debugging on small scale data - often by taking a suitable (say 0.1 - 1%) sample of the full data. The same basic steps can then be repeated with much larger datasets in cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "First run the following steps only if you are running Datalab from your local desktop or laptop (not running Datalab from a GCE VM):\n",
    "\n",
    "1. Make sure you have a GCP project which is enabled for Machine Learning API and Dataflow API.\n",
    "2. Run \"%datalab project set --project [project-id]\" to set the default project in Datalab.\n",
    "\n",
    "If you run Datalab from a GCE VM, then make sure the project of the GCE VM is enabled for Machine Learning API and Dataflow API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mltoolbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0808a6393ce6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmltoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gs://'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdatalab_project_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-lab'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpreprocess_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/flowerpreprocessedcloud'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mltoolbox'"
     ]
    }
   ],
   "source": [
    "import mltoolbox.image.classification as model\n",
    "from google.datalab.ml import *\n",
    "\n",
    "bucket = 'gs://' + datalab_project_id() + '-lab'\n",
    "preprocess_dir = bucket + '/flowerpreprocessedcloud'\n",
    "model_dir = bucket + '/flowermodelcloud'\n",
    "staging_dir = bucket + '/staging'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil mb $bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "Preprocessing uses a Dataflow pipeline to convert the image format, resize images, and run the converted image through a pre-trained model to get the features or embeddings. You can also do this step using alternate technologies like Spark or plain Python code if you like. \n",
    "The %%ml preprocess command simplifies this task. Check out the parameters shown using --usage flag first and then run the command."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you hit \"PERMISSION_DENIED\" when running the following cell, you need to enable Cloud DataFlow API (url is shown in error message). \n",
    "\n",
    "The DataFlow job usually takes about 20 min to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CsvDataSet('gs://cloud-datalab/sampledata/flower/train1000.csv', schema='image_url:STRING,label:STRING')\n",
    "preprocess_job = model.preprocess_async(train_set, preprocess_dir, cloud={'num_workers': 10})\n",
    "preprocess_job.wait() # Alternatively, you can query the job status by train_job.state. The wait() call blocks the notebook execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Note that the command remains the same as that in the \"local\" version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_job = model.train_async(preprocess_dir, 30, 1000, model_dir, cloud=CloudTrainingConfig('us-central1', 'BASIC'))\n",
    "train_job.wait() # Alternatively, you can query the job status by train_job.state. The wait() call blocks the notebook execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your job status by running (replace the job id from the one shown above):\n",
    "```\n",
    "Job('image_classification_train_170307_002934').describe()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorboard works too with GCS path. Note that the data will show up usually a minute after tensorboard starts with GCS path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_id = TensorBoard.start(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict\n",
    "Deploy the model and run online predictions. The deployment takes about 2 ~ 5 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Models().create('flower')\n",
    "ModelVersions('flower').deploy('beta1', model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Online prediction is currently in alpha, it helps to ensure a warm start if the first call fails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    'gs://cloud-ml-data/img/flower_photos/daisy/15207766_fc2f1d692c_n.jpg',\n",
    "    'gs://cloud-ml-data/img/flower_photos/tulips/6876631336_54bf150990.jpg'\n",
    "]\n",
    "# set resize=True to avoid sending large data in prediction request.\n",
    "model.predict('flower.beta1', images, resize=True, cloud=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "\n",
    "bq.Dataset('flower').create()\n",
    "eval_set = CsvDataSet('gs://cloud-datalab/sampledata/flower/eval670.csv', schema='image_url:STRING,label:STRING')\n",
    "batch_predict_job = model.batch_predict_async(eval_set, model_dir, output_bq_table='flower.eval_results_full',\n",
    "                                              cloud={'temp_location': staging_dir})\n",
    "batch_predict_job.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq query --name wrong_prediction\n",
    "\n",
    "SELECT * FROM flower.eval_results_full WHERE target != predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_prediction.execute().result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix.from_bigquery('flower.eval_results_full').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq query --name accuracy\n",
    "\n",
    "SELECT\n",
    "  target,\n",
    "  SUM(CASE WHEN target=predicted THEN 1 ELSE 0 END) as correct,\n",
    "  COUNT(*) as total,\n",
    "  SUM(CASE WHEN target=predicted THEN 1 ELSE 0 END)/COUNT(*) as accuracy\n",
    "FROM\n",
    "  flower.eval_results_full\n",
    "GROUP BY\n",
    "  target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.execute().result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq query --name logloss\n",
    "\n",
    "SELECT feature, AVG(-logloss) as logloss, count(*) as count FROM\n",
    "(\n",
    "SELECT feature, CASE WHEN correct=1 THEN LOG(prob) ELSE LOG(1-prob) END as logloss\n",
    "FROM\n",
    "(\n",
    "SELECT\n",
    "target as feature, \n",
    "CASE WHEN target=predicted THEN 1 ELSE 0 END as correct,\n",
    "target_prob as prob\n",
    "FROM flower.eval_results_full))\n",
    "GROUP BY feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSliceView().plot(logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelVersions('flower').delete('beta1')\n",
    "Models().delete('flower')\n",
    "!gsutil -m rm -r {preprocess_dir}\n",
    "!gsutil -m rm -r {model_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalab-notebooks",
   "language": "python",
   "name": "datalab-notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
