{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "For local run, we cannot afford running with full data. We will sample the data randomly (using hash) to about 200~300 instances. It takes about 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mltoolbox'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5008b1342306>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmltoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatalab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mml\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mworker_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/datalab/tmp/coast'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpreprocessed_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/coast300'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mltoolbox'"
     ]
    }
   ],
   "source": [
    "import mltoolbox.image.classification as model\n",
    "from google.datalab.ml import *\n",
    "\n",
    "worker_dir = '/content/datalab/tmp/coast'\n",
    "preprocessed_dir = worker_dir + '/coast300'\n",
    "model_dir = worker_dir + '/model300'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = BigQueryDataSet('SELECT image_url, label FROM coast.train WHERE rand() < 0.04')\n",
    "model.preprocess(train_set, preprocessed_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "To get help of a certain method, run 'mymethod??' and on the right side you will see the method signature. For example, run 'local_train??'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "model.train(preprocessed_dir, 30, 1000, model_dir)\n",
    "logging.getLogger().setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start hosted Tensorboard to check events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_id = TensorBoard.start(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Our model was trained with a small subset of the data so accuracy is not very high.\n",
    "\n",
    "First, we can check the TF summary events from training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = Summary(model_dir)\n",
    "summary.list_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.plot('accuracy')\n",
    "summary.plot('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do more evaluation with more data using batch prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction\n",
    "\n",
    "Instant prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs://tamucc_coastline/esi_images/IMG_2849_SecDE_Spr12.jpg,3B\n",
    "# gs://tamucc_coastline/esi_images/IMG_0047_SecBC_Spr12.jpg,10A\n",
    "# gs://tamucc_coastline/esi_images/IMG_0617_SecBC_Spr12.jpg,7\n",
    "# gs://tamucc_coastline/esi_images/IMG_2034_SecEGH_Sum12_Pt2.jpg,10A\n",
    "images = [\n",
    "  'gs://tamucc_coastline/esi_images/IMG_2849_SecDE_Spr12.jpg',\n",
    "  'gs://tamucc_coastline/esi_images/IMG_0047_SecBC_Spr12.jpg',\n",
    "  'gs://tamucc_coastline/esi_images/IMG_0617_SecBC_Spr12.jpg',\n",
    "  'gs://tamucc_coastline/esi_images/IMG_2034_SecEGH_Sum12_Pt2.jpg'\n",
    "]\n",
    "# Set show_image to True to see the images\n",
    "model.predict(model_dir, images, show_image=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch prediction. Note that we sample eval data so we use about 200 instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set = BigQueryDataSet('select * from coast.eval WHERE rand()<0.1')\n",
    "model.batch_predict(eval_set, model_dir, output_bq_table='coast.eval200tinymodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrix.from_bigquery('select * from coast.eval200tinymodel').plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute accuracy per label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq query --name accuracy\n",
    "SELECT\n",
    "  target,\n",
    "  SUM(CASE WHEN target=predicted THEN 1 ELSE 0 END) as correct,\n",
    "  COUNT(*) as total,\n",
    "  SUM(CASE WHEN target=predicted THEN 1 ELSE 0 END)/COUNT(*) as accuracy\n",
    "FROM\n",
    "  coast.eval200tinymodel\n",
    "GROUP BY\n",
    "  target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy.execute().result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the results using Feature-Slice-View. This time do logloss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq query --name logloss\n",
    "\n",
    "SELECT feature, AVG(-logloss) as logloss, COUNT(*) as count FROM\n",
    "(\n",
    "  SELECT feature, CASE WHEN correct=1 THEN LOG(prob) ELSE LOG(1-prob) END as logloss\n",
    "  FROM\n",
    "  (\n",
    "    SELECT\n",
    "    target as feature, \n",
    "    CASE WHEN target=predicted THEN 1 ELSE 0 END as correct,\n",
    "    target_prob as prob\n",
    "    FROM coast.eval200tinymodel\n",
    "  )\n",
    ")\n",
    "GROUP BY feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatureSliceView().plot(logloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import google.datalab.bigquery as bq\n",
    "\n",
    "TensorBoard.stop(tb_id)\n",
    "bq.Table('coast.eval200tinymodel').delete()\n",
    "shutil.rmtree(worker_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalab-notebooks",
   "language": "python",
   "name": "datalab-notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
