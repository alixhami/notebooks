{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection in HTTP Logs\n",
    "\n",
    "This sample notebook demonstrates working with HTTP request logs data stored in BigQuery.\n",
    "\n",
    "Google Cloud Logging in the Google Cloud Platform makes it simple to export HTTP request logs from AppEngine applications directly into BigQuery for further analysis. This log data includes information such as the requested resource, HTTP status code, etc. One possible use of these logs is to mine them as they are collected to detect anomalies in response latency, since this can be a signal for some unexpected deployment issue.\n",
    "\n",
    "The sample data used in this notebook is similar to AppEngine logs. It represents anonymized HTTP logs from a hypothetical application.\n",
    "\n",
    "Related Links:\n",
    "\n",
    "* [Cloud Logging](https://cloud.google.com/logging/docs/)\n",
    "* [BigQuery](https://cloud.google.com/bigquery/what-is-bigquery)\n",
    "* [Pandas](http://pandas.pydata.org/) for data analysis\n",
    "* [Matplotlib](http://matplotlib.org/) for data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import google.datalab.bigquery as bq\n",
    "import matplotlib.pyplot as plot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Logs Data\n",
    "\n",
    "It's helpful to inspect the dataset, the schema, and a sample of the data we're working with. Usually, logs are captured as multiple tables within a dataset, with new tables added per time window (such as daily logs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext google.datalab.kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ul><li>cloud-datalab-samples.httplogs.logs_20140615</li><li>cloud-datalab-samples.httplogs.logs_20140616</li><li>cloud-datalab-samples.httplogs.logs_20140617</li><li>cloud-datalab-samples.httplogs.logs_20140618</li><li>cloud-datalab-samples.httplogs.logs_20140619</li><li>cloud-datalab-samples.httplogs.logs_20140620</li></ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%bq tables list --project cloud-datalab-samples --dataset httplogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bqsv\" id=\"1_154510053772\"></div>\n",
       "    <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "    <script>\n",
       "      require.config({\n",
       "        paths: {\n",
       "          base: '/static/base',\n",
       "        },\n",
       "        map: {\n",
       "          '*': {\n",
       "            datalab: 'nbextensions/gcpdatalab'\n",
       "          }\n",
       "        },\n",
       "      });\n",
       "\n",
       "      require(['datalab/bigquery', 'datalab/element!1_154510053772',\n",
       "          'datalab/style!/nbextensions/gcpdatalab/bigquery.css'],\n",
       "        function(bq, dom) {\n",
       "          bq.renderSchema(dom, [{\"name\": \"timestamp\", \"type\": \"TIMESTAMP\"}, {\"name\": \"latency\", \"type\": \"INTEGER\"}, {\"name\": \"status\", \"type\": \"INTEGER\"}, {\"name\": \"method\", \"type\": \"STRING\"}, {\"name\": \"endpoint\", \"type\": \"STRING\"}]);\n",
       "        }\n",
       "      );\n",
       "    </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%bq tables describe -n cloud-datalab-samples.httplogs.logs_20140615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq query -n logs\n",
    "SELECT timestamp, latency, status, method, endpoint\n",
    "FROM `cloud-datalab-samples.httplogs.logs_20140615`\n",
    "ORDER by timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bqtv\" id=\"2_154510054049\"><table><tr><th>timestamp</th><th>latency</th><th>status</th><th>method</th><th>endpoint</th></tr><tr><td>2014-06-15 07:00:00.003772</td><td>122</td><td>200</td><td>GET</td><td>Interact3</td></tr><tr><td>2014-06-15 07:00:00.428897</td><td>144</td><td>200</td><td>GET</td><td>Interact3</td></tr><tr><td>2014-06-15 07:00:00.536486</td><td>48</td><td>200</td><td>GET</td><td>Interact3</td></tr><tr><td>2014-06-15 07:00:00.652760</td><td>28</td><td>405</td><td>GET</td><td>Interact2</td></tr><tr><td>2014-06-15 07:00:00.670100</td><td>103</td><td>200</td><td>GET</td><td>Interact3</td></tr><tr><td>2014-06-15 07:00:00.834251</td><td>121</td><td>405</td><td>GET</td><td>Interact2</td></tr><tr><td>2014-06-15 07:00:00.943075</td><td>28</td><td>200</td><td>GET</td><td>Other</td></tr></table></div>\n",
       "    <br />(rows: 7, time: 0.6s,    24MB processed, job: job_VCb8h5Fd6CdQG3Nli0L3qh5m75UV)<br />\n",
       "    <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "    <script>\n",
       "      require.config({\n",
       "        paths: {\n",
       "          base: '/static/base',\n",
       "          d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.13/d3',\n",
       "          plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
       "          jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min'\n",
       "        },\n",
       "        map: {\n",
       "          '*': {\n",
       "            datalab: 'nbextensions/gcpdatalab'\n",
       "          }\n",
       "        },\n",
       "        shim: {\n",
       "          plotly: {\n",
       "            deps: ['d3', 'jquery'],\n",
       "            exports: 'plotly'\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "\n",
       "      require(['datalab/charting', 'datalab/element!2_154510054049', 'base/js/events',\n",
       "          'datalab/style!/nbextensions/gcpdatalab/charting.css'],\n",
       "        function(charts, dom, events) {\n",
       "          charts.render('gcharts', dom, events, 'table', [], {\"cols\": [{\"id\": \"timestamp\", \"label\": \"timestamp\", \"type\": \"timestamp\"}, {\"id\": \"latency\", \"label\": \"latency\", \"type\": \"number\"}, {\"id\": \"status\", \"label\": \"status\", \"type\": \"number\"}, {\"id\": \"method\", \"label\": \"method\", \"type\": \"string\"}, {\"id\": \"endpoint\", \"label\": \"endpoint\", \"type\": \"string\"}], \"rows\": [{\"c\": [{\"v\": \"2014-06-15T07:00:00.003772\"}, {\"v\": 122}, {\"v\": 200}, {\"v\": \"GET\"}, {\"v\": \"Interact3\"}]}, {\"c\": [{\"v\": \"2014-06-15T07:00:00.428897\"}, {\"v\": 144}, {\"v\": 200}, {\"v\": \"GET\"}, {\"v\": \"Interact3\"}]}, {\"c\": [{\"v\": \"2014-06-15T07:00:00.536486\"}, {\"v\": 48}, {\"v\": 200}, {\"v\": \"GET\"}, {\"v\": \"Interact3\"}]}, {\"c\": [{\"v\": \"2014-06-15T07:00:00.652760\"}, {\"v\": 28}, {\"v\": 405}, {\"v\": \"GET\"}, {\"v\": \"Interact2\"}]}, {\"c\": [{\"v\": \"2014-06-15T07:00:00.670100\"}, {\"v\": 103}, {\"v\": 200}, {\"v\": \"GET\"}, {\"v\": \"Interact3\"}]}, {\"c\": [{\"v\": \"2014-06-15T07:00:00.834251\"}, {\"v\": 121}, {\"v\": 405}, {\"v\": \"GET\"}, {\"v\": \"Interact2\"}]}, {\"c\": [{\"v\": \"2014-06-15T07:00:00.943075\"}, {\"v\": 28}, {\"v\": 200}, {\"v\": \"GET\"}, {\"v\": \"Other\"}]}]},\n",
       "            {\n",
       "              pageSize: 25,\n",
       "              cssClassNames:  {\n",
       "                tableRow: 'gchart-table-row',\n",
       "                headerRow: 'gchart-table-headerrow',\n",
       "                oddTableRow: 'gchart-table-oddrow',\n",
       "                selectedTableRow: 'gchart-table-selectedrow',\n",
       "                hoverTableRow: 'gchart-table-hoverrow',\n",
       "                tableCell: 'gchart-table-cell',\n",
       "                headerCell: 'gchart-table-headercell',\n",
       "                rowNumberCell: 'gchart-table-rownumcell'\n",
       "              }\n",
       "            },\n",
       "            {source_index: 0, fields: 'timestamp,latency,status,method,endpoint'},\n",
       "            0,\n",
       "            7);\n",
       "        }\n",
       "      );\n",
       "    </script>\n",
       "  "
      ],
      "text/plain": [
       "QueryResultsTable job_VCb8h5Fd6CdQG3Nli0L3qh5m75UV"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bq sample --query logs --count 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforming Logs into a Time Series\n",
    "\n",
    "We're going to build a timeseries over latency. In order to make it a useful metric, we'll look at 99th percentile latency of requests within a fixed 5min window using this SQL query issued to BigQuery (notice the grouping over a truncated timestamp, and quantile aggregation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bq query -n timeseries\n",
    "SELECT DIV(UNIX_SECONDS(timestamp), 300) * 300 AS five_minute_window,\n",
    "       APPROX_QUANTILES(latency, 99)[SAFE_ORDINAL(99)] as latency\n",
    "FROM `cloud-datalab-samples.httplogs.logs_20140615`\n",
    "WHERE endpoint = 'Recent'\n",
    "GROUP BY five_minute_window\n",
    "ORDER by five_minute_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bqtv\" id=\"3_154510054399\"><table><tr><th>five_minute_window</th><th>latency</th></tr><tr><td>1402815600</td><td>427</td></tr><tr><td>1402815900</td><td>329</td></tr><tr><td>1402816200</td><td>293</td></tr><tr><td>1402817400</td><td>242</td></tr><tr><td>1402818000</td><td>332</td></tr><tr><td>1402818300</td><td>288</td></tr><tr><td>1402818900</td><td>299</td></tr><tr><td>1402819800</td><td>294</td></tr><tr><td>1402820400</td><td>111</td></tr><tr><td>1402821000</td><td>361</td></tr></table></div>\n",
       "    <br />(rows: 10, time: 0.6s,    15MB processed, job: job_g7cAkW05IqjLTG2XojrILpzlqmHt)<br />\n",
       "    <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "    <script>\n",
       "      require.config({\n",
       "        paths: {\n",
       "          base: '/static/base',\n",
       "          d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.13/d3',\n",
       "          plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
       "          jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min'\n",
       "        },\n",
       "        map: {\n",
       "          '*': {\n",
       "            datalab: 'nbextensions/gcpdatalab'\n",
       "          }\n",
       "        },\n",
       "        shim: {\n",
       "          plotly: {\n",
       "            deps: ['d3', 'jquery'],\n",
       "            exports: 'plotly'\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "\n",
       "      require(['datalab/charting', 'datalab/element!3_154510054399', 'base/js/events',\n",
       "          'datalab/style!/nbextensions/gcpdatalab/charting.css'],\n",
       "        function(charts, dom, events) {\n",
       "          charts.render('gcharts', dom, events, 'table', [], {\"cols\": [{\"id\": \"five_minute_window\", \"label\": \"five_minute_window\", \"type\": \"number\"}, {\"id\": \"latency\", \"label\": \"latency\", \"type\": \"number\"}], \"rows\": [{\"c\": [{\"v\": 1402815600}, {\"v\": 427}]}, {\"c\": [{\"v\": 1402815900}, {\"v\": 329}]}, {\"c\": [{\"v\": 1402816200}, {\"v\": 293}]}, {\"c\": [{\"v\": 1402817400}, {\"v\": 242}]}, {\"c\": [{\"v\": 1402818000}, {\"v\": 332}]}, {\"c\": [{\"v\": 1402818300}, {\"v\": 288}]}, {\"c\": [{\"v\": 1402818900}, {\"v\": 299}]}, {\"c\": [{\"v\": 1402819800}, {\"v\": 294}]}, {\"c\": [{\"v\": 1402820400}, {\"v\": 111}]}, {\"c\": [{\"v\": 1402821000}, {\"v\": 361}]}]},\n",
       "            {\n",
       "              pageSize: 25,\n",
       "              cssClassNames:  {\n",
       "                tableRow: 'gchart-table-row',\n",
       "                headerRow: 'gchart-table-headerrow',\n",
       "                oddTableRow: 'gchart-table-oddrow',\n",
       "                selectedTableRow: 'gchart-table-selectedrow',\n",
       "                hoverTableRow: 'gchart-table-hoverrow',\n",
       "                tableCell: 'gchart-table-cell',\n",
       "                headerCell: 'gchart-table-headercell',\n",
       "                rowNumberCell: 'gchart-table-rownumcell'\n",
       "              }\n",
       "            },\n",
       "            {source_index: 1, fields: 'five_minute_window,latency'},\n",
       "            0,\n",
       "            10);\n",
       "        }\n",
       "      );\n",
       "    </script>\n",
       "  "
      ],
      "text/plain": [
       "QueryResultsTable job_g7cAkW05IqjLTG2XojrILpzlqmHt"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bq sample --query timeseries --count 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Time Series Data\n",
    "\n",
    "Its helpful to visualize the data. In order to visualize this timeseries, we'll use python, pandas and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute and convert the results to a Pandas dataframe\n",
    "timeseries_df = timeseries.execute(output_options=bq.QueryOutput.dataframe()).result()\n",
    "\n",
    "timeseries_values = timeseries_df['latency'].values\n",
    "timeseries_len = len(timeseries_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot(np.array(range(timeseries_len)), timeseries_values)\n",
    "plot.yscale('log')\n",
    "plot.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A visual inspection of the chart, above, highlights the obvious anomalies, but we want to construct something that can inspect the data, learn from it, and detect anomalies in an automated way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detector\n",
    "\n",
    "The code below is a simple anomaly detector created for purposes of a sample. It uses a simple algorithm that tracks mean and standard deviation. You can give it a value indicating the number of instances is uses to train a model before it starts detecting anomalies. As new values are passed to it, it continues to update the model (to account for slowly evolving changes) and report anomalies. Any value that is off from the mean by 3x the standard deviation is considered as an anomaly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDetector(object):\n",
    "\n",
    "  def __init__(self, window = 10):\n",
    "    self._index = 0\n",
    "    self._window = window\n",
    "    self._values = np.zeros(window)\n",
    "    self._valuesSq = np.zeros(window)\n",
    "    self._mean = 0\n",
    "    self._variance = 0\n",
    "    self._count = 0\n",
    "\n",
    "  def observation(self, value):\n",
    "    anomaly = False\n",
    "\n",
    "    threshold = 3 * np.sqrt(self._variance)\n",
    "    if self._count > self._window:\n",
    "      if value > self._mean + threshold:\n",
    "        value = self._mean + threshold\n",
    "        anomaly = True\n",
    "      elif value < self._mean - threshold:\n",
    "        value = self._mean - threshold\n",
    "        anomaly = True\n",
    "    else:\n",
    "      self._count += 1\n",
    "\n",
    "    prev_value = self._values[self._index]\n",
    "    self._values[self._index] = value\n",
    "    self._valuesSq[self._index] = value ** 2\n",
    "    self._index = (self._index + 1) % self._window\n",
    "\n",
    "    self._mean = self._mean - prev_value / self._window + value / self._window\n",
    "    self._variance = sum(self._valuesSq) / self._window - (self._mean ** 2)\n",
    "\n",
    "    return anomaly, self._mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the anomaly detector implemented, let's run the timeseries through it to collect any anomalies and the expected mean along each point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = np.zeros(timeseries_len)\n",
    "means = np.zeros(timeseries_len)\n",
    "\n",
    "anomaly_detector = AnomalyDetector(36)\n",
    "\n",
    "for i, value in enumerate(timeseries_values):\n",
    "  anomaly, mean = anomaly_detector.observation(value)\n",
    "    \n",
    "  anomalies[i] = anomaly\n",
    "  means[i] = mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, plot the same time series, but overlay the anomalies and the mean values as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticks = np.array(range(timeseries_len))\n",
    "\n",
    "plot.plot(ticks, timeseries_values)\n",
    "plot.plot(ticks[anomalies == 1], timeseries_values[anomalies == 1], 'ro')\n",
    "plot.plot(ticks, means, 'g', linewidth = 1)\n",
    "plot.yscale('log')\n",
    "plot.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going Beyond the Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample demonstrated how to use SQL to transform raw log data into an interesting timeseries, then apply Python logic to detect and visualize anomalies.\n",
    "\n",
    "Here are some next steps that to make this exercise more useful.\n",
    "\n",
    "* Build an initial model based on training data over a representative time, then store that model.\n",
    "\n",
    "* Parameterize the source table of the logs. You'll want to use a table that is date based, and use a table decorater to convert the last N minutes of log data into a single timeseries point.\n",
    "\n",
    "* Pass the resulting timeseries point into an anomaly detector that uses the stored model, then publishes anomalies to a pub/sub topic.\n",
    "\n",
    "The notebook allows you to work with your data to explore and understand it, working through the steps to derive data and arrive at a proof of concept that you can take to build a final solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datalab-notebooks",
   "language": "python",
   "name": "datalab-notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
